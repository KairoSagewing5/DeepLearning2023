{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYuALZOG-AMq"
   },
   "source": [
    "## Assignment: Image recognition\n",
    "- Alumno 1: Alberto Gómez Jiménez\n",
    "- Alumno 2: Seong-Min Gong\n",
    "- Alumno 3:\n",
    "\n",
    "The goals of the assignment are:\n",
    "* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n",
    "* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem (28th Feb - 7th Mar).\n",
    "* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task (7th Mar - 14th Mar).\n",
    "* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning (14th Mar - 23rd Mar)\n",
    "\n",
    "Follow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/UeDNT7JEYFkCVPP](https://drive.upm.es/s/UeDNT7JEYFkCVPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "OYtqD3Oh-AMw"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "class GenericObject:\n",
    "    \"\"\"\n",
    "    Generic object data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.bb = (-1, -1, -1, -1)\n",
    "        self.category= -1\n",
    "        self.score = -1\n",
    "\n",
    "class GenericImage:\n",
    "    \"\"\"\n",
    "    Generic image data.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
    "        self.objects = list([])\n",
    "\n",
    "    def add_object(self, obj: GenericObject):\n",
    "        self.objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "I_GygShu-AMz"
   },
   "outputs": [],
   "source": [
    "categories = {0: 'CARGO_PLANE', 1: 'HELICOPTER', 2: 'SMALL_CAR', 3: 'BUS', 4: 'TRUCK', 5: 'MOTORBOAT', 6: 'FISHING_VESSEL', 7: 'DUMP_TRUCK', 8: 'EXCAVATOR', 9: 'BUILDING', 10: 'STORAGE_TANK', 11: 'SHIPPING_CONTAINER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "fRBA7ReQ-AM0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_geoimage(filename):\n",
    "    warnings.filterwarnings('ignore', category = rasterio.errors.NotGeoreferencedWarning)\n",
    "    src_raster = rasterio.open(filename, 'r')\n",
    "    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n",
    "    input_type = src_raster.profile['dtype']\n",
    "    input_channels = src_raster.count\n",
    "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
    "    for band in range(input_channels):\n",
    "        img[:, :, band] = src_raster.read(band+1)\n",
    "    return img\n",
    "\n",
    "def generator_images(objs, batch_size, do_shuffle = False):\n",
    "    while True:\n",
    "        if do_shuffle:\n",
    "            np.random.shuffle(objs)\n",
    "        groups = [objs[i:i+batch_size] for i in range(0, len(objs), batch_size)]\n",
    "        for group in groups:\n",
    "            images, labels = [], []\n",
    "            for (filename, obj) in group:\n",
    "                # Load image\n",
    "                images.append(load_geoimage(filename))\n",
    "                probabilities = np.zeros(len(categories))\n",
    "                probabilities[list(categories.values()).index(obj.category)] = 1\n",
    "                labels.append(probabilities)\n",
    "            images = np.array(images).astype(np.float32)\n",
    "            labels = np.array(labels).astype(np.float32)\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "HAanJ-V0-AM1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def draw_confusion_matrix(cm, categories):\n",
    "    # Draw confusion matrix\n",
    "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n",
    "    fig.tight_layout()\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diNBB3qy-AM2"
   },
   "source": [
    "#### Training\n",
    "Design and train a CNN to deal with the “xview_recognition” classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Orto292C-AM3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load database\n",
    "json_file = 'xview_ann_train.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "4GjFLHs4-AM4",
    "outputId": "5581df22-d4e9-42ac-9f94-061fd8c7acd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CARGO_PLANE': 635, 'HELICOPTER': 70, 'SMALL_CAR': 11675, 'BUS': 4017, 'TRUCK': 5836, 'MOTORBOAT': 571, 'FISHING_VESSEL': 457, 'DUMP_TRUCK': 1108, 'EXCAVATOR': 741, 'BUILDING': 13011, 'STORAGE_TANK': 1249, 'SHIPPING_CONTAINER': 816}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = dict.fromkeys(categories.values(), 0)\n",
    "anns = []\n",
    "for json_img, json_ann in zip(json_data['images'], json_data['annotations']):\n",
    "    image = GenericImage(json_img['file_name'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    obj = GenericObject()\n",
    "    obj.id = json_ann['id']\n",
    "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "    obj.category = list(categories.values())[json_ann['category_id']-1]\n",
    "    # Resampling strategy to reduce training time\n",
    "    counts[obj.category] += 1\n",
    "    image.add_object(obj)\n",
    "    anns.append(image)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "NriAECvS-AM6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "anns_train, anns_valid = train_test_split(anns, test_size=0.1, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, \\\n",
    "                        ZeroPadding2D, Conv2D, BatchNormalization, Add, AveragePooling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\"\"\"\n",
    "def relu_batch_adder(inputs):\n",
    "    out = Activation('gelu')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    return out\n",
    "\n",
    "def residual(x, downsample, filters, kernel_size = 3):\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_batch_adder(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_batch_adder(out)\n",
    "    return out\n",
    "    \"\"\"\n",
    "def residual_block(x, number_of_filters, match_filter_size=False):\n",
    "   \n",
    "    #Residual block with\n",
    "    \n",
    "    # Retrieve initializer\n",
    "    initializer = HeNormal()\n",
    "\n",
    "    # Create skip connection\n",
    "    x_skip = x\n",
    "\n",
    "    # Perform the original mapping\n",
    "    if match_filter_size:\n",
    "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2,2),\\\n",
    "            kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
    "    else:\n",
    "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1,1),\\\n",
    "            kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(number_of_filters, kernel_size=(3, 3),\\\n",
    "        kernel_initializer=initializer, padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if match_filter_size:\n",
    "        x_skip = Conv2D(number_of_filters, kernel_size=(1,1),\\\n",
    "            kernel_initializer=initializer, strides=(2,2))(x_skip)\n",
    "    \n",
    "    # Add the skip connection to the regular mapping\n",
    "    x = Add()([x, x_skip])\n",
    "\n",
    "    # Nonlinearly activate the result\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Return the result\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResidualBlocks(x):\n",
    "    \"\"\"\n",
    "        Set up the residual blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set initial filter size\n",
    "    filter_size = 16\n",
    "\n",
    "    # Paper: \"Then we use a stack of 6n layers (...)\n",
    "    #    with 2n layers for each feature map size.\"\n",
    "    # 6n/2n = 3, so there are always 3 groups.\n",
    "    for layer_group in range(3):\n",
    "\n",
    "        # Each block in our code has 2 weighted layers,\n",
    "        # and each group has 2n such blocks,\n",
    "        # so 2n/2 = n blocks per group.\n",
    "        for block in range(3):\n",
    "\n",
    "            # Perform filter size increase at every\n",
    "            # first layer in the 2nd block onwards.\n",
    "            # Apply Conv block for projecting the skip\n",
    "            # connection.\n",
    "            if layer_group > 0 and block == 0:\n",
    "                filter_size *= 2\n",
    "                x = residual_block(x, filter_size, match_filter_size=True)\n",
    "            else:\n",
    "                x = residual_block(x, filter_size)\n",
    "\n",
    "    # Return final layer\n",
    "    return x\n",
    "\n",
    "def model_base(shp):\n",
    "    \"\"\"\n",
    "        Base structure of the model, with residual blocks\n",
    "        attached.\n",
    "    \"\"\"\n",
    "    # Get number of classes from model configuration\n",
    "    initializer = HeNormal()\n",
    "\n",
    "    # Define model structure\n",
    "    # logits are returned because Softmax is pushed to loss function.\n",
    "    inputs = Input(shape = shp)\n",
    "    x = Conv2D(16, kernel_size=(3,3),\\\n",
    "        strides=(1,1), kernel_initializer=initializer, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = ResidualBlocks(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(12, kernel_initializer = initializer)(x)\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "BNkjbY2e-AM7",
    "outputId": "47bde031-306f-464e-8e22-cc70a7fb7c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kairo\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 224, 224, 16  448         ['input_21[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 224, 224, 16  64         ['conv2d_263[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 224, 224, 16  0           ['batch_normalization_247[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 224, 224, 16  2320        ['activation_231[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 224, 224, 16  64         ['conv2d_264[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 224, 224, 16  0           ['batch_normalization_248[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 224, 224, 16  2320        ['activation_232[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 224, 224, 16  64         ['conv2d_265[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " add_107 (Add)                  (None, 224, 224, 16  0           ['batch_normalization_249[0][0]',\n",
      "                                )                                 'activation_231[0][0]']         \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 224, 224, 16  0           ['add_107[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 224, 224, 16  2320        ['activation_233[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 224, 224, 16  64         ['conv2d_266[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 224, 224, 16  0           ['batch_normalization_250[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 224, 224, 16  2320        ['activation_234[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 224, 224, 16  64         ['conv2d_267[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " add_108 (Add)                  (None, 224, 224, 16  0           ['batch_normalization_251[0][0]',\n",
      "                                )                                 'activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 224, 224, 16  0           ['add_108[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 224, 224, 16  2320        ['activation_235[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 224, 224, 16  64         ['conv2d_268[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 224, 224, 16  0           ['batch_normalization_252[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 224, 224, 16  2320        ['activation_236[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 224, 224, 16  64         ['conv2d_269[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " add_109 (Add)                  (None, 224, 224, 16  0           ['batch_normalization_253[0][0]',\n",
      "                                )                                 'activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 224, 224, 16  0           ['add_109[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 112, 112, 32  4640        ['activation_237[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 112, 112, 32  128        ['conv2d_270[0][0]']             \n",
      " Normalization)                 )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 112, 112, 32  0           ['batch_normalization_254[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 112, 112, 32  9248        ['activation_238[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 112, 112, 32  128        ['conv2d_271[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 112, 112, 32  544         ['activation_237[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_110 (Add)                  (None, 112, 112, 32  0           ['batch_normalization_255[0][0]',\n",
      "                                )                                 'conv2d_272[0][0]']             \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 112, 112, 32  0           ['add_110[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 112, 112, 32  9248        ['activation_239[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 112, 112, 32  128        ['conv2d_273[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 112, 112, 32  0           ['batch_normalization_256[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 112, 112, 32  9248        ['activation_240[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 112, 112, 32  128        ['conv2d_274[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " add_111 (Add)                  (None, 112, 112, 32  0           ['batch_normalization_257[0][0]',\n",
      "                                )                                 'activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 112, 112, 32  0           ['add_111[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 112, 112, 32  9248        ['activation_241[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 112, 112, 32  128        ['conv2d_275[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 112, 112, 32  0           ['batch_normalization_258[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 112, 112, 32  9248        ['activation_242[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 112, 112, 32  128        ['conv2d_276[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " add_112 (Add)                  (None, 112, 112, 32  0           ['batch_normalization_259[0][0]',\n",
      "                                )                                 'activation_241[0][0]']         \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 112, 112, 32  0           ['add_112[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 56, 56, 64)   18496       ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 56, 56, 64)  256         ['conv2d_277[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 56, 56, 64)   0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 56, 56, 64)   36928       ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 56, 56, 64)  256         ['conv2d_278[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 56, 56, 64)   2112        ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " add_113 (Add)                  (None, 56, 56, 64)   0           ['batch_normalization_261[0][0]',\n",
      "                                                                  'conv2d_279[0][0]']             \n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 56, 56, 64)   0           ['add_113[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 56, 56, 64)   36928       ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 56, 56, 64)  256         ['conv2d_280[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 56, 56, 64)   0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 56, 56, 64)   36928       ['activation_246[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 56, 56, 64)  256         ['conv2d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_114 (Add)                  (None, 56, 56, 64)   0           ['batch_normalization_263[0][0]',\n",
      "                                                                  'activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 56, 56, 64)   0           ['add_114[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)            (None, 56, 56, 64)   36928       ['activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 56, 56, 64)  256         ['conv2d_282[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 56, 56, 64)   0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)            (None, 56, 56, 64)   36928       ['activation_248[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 56, 56, 64)  256         ['conv2d_283[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_115 (Add)                  (None, 56, 56, 64)   0           ['batch_normalization_265[0][0]',\n",
      "                                                                  'activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 56, 56, 64)   0           ['add_115[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 64)          0           ['activation_249[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 64)           0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 12)           780         ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 274,572\n",
      "Trainable params: 273,196\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Load model')\n",
    "\"\"\"\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "num_filters = 64\n",
    "\n",
    "t = BatchNormalization()(inputs)\n",
    "t = Conv2D(kernel_size=3,\n",
    "           strides=1,\n",
    "           filters=num_filters,\n",
    "           padding=\"same\")(t)\n",
    "t = relu_batch_adder(t)\n",
    "\n",
    "num_blocks_list = [2, 5, 5, 2]\n",
    "for i in range(len(num_blocks_list)):\n",
    "    num_blocks = num_blocks_list[i]\n",
    "    for j in range(num_blocks):\n",
    "        t = residual(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "    num_filters *= 2\n",
    "\n",
    "t = AveragePooling2D(4)(t)\n",
    "t = Flatten()(t)\n",
    "outputs = Dense(12, activation='softmax')(t)\n",
    "\"\"\"\n",
    "\n",
    "inputs, outputs = model_base((224, 224, 3))\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "-aSlKtG6-AM7"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Learning rate is changed to 0.001\n",
    "model.compile(optimizer = \"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "GGAJEfpB-AM8"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint('model_resnet_1.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.1, patience=10, verbose=1)\n",
    "early_stop = EarlyStopping('val_accuracy', patience=40, verbose=1)\n",
    "terminate = TerminateOnNaN()\n",
    "callbacks = [model_checkpoint, reduce_lr, early_stop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Yht-QqUH-AM8"
   },
   "outputs": [],
   "source": [
    "# Generate the list of objects from annotations\n",
    "objs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\n",
    "objs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n",
    "# Generators\n",
    "batch_size = 128\n",
    "train_generator = generator_images(objs_train, batch_size, do_shuffle=True)\n",
    "valid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrfpdECs-AM9",
    "outputId": "21d89b78-d94c-442e-9bc2-517654c0b614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 1/10\n",
      "  2/283 [..............................] - ETA: 1:41:35 - loss: 9.0035 - accuracy: 0.0977"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "print('Training model')\n",
    "epochs = 10\n",
    "train_steps = math.ceil(len(objs_train)/batch_size)\n",
    "valid_steps = math.ceil(len(objs_valid)/batch_size)\n",
    "h = model.fit(train_generator, steps_per_epoch=train_steps, validation_data=valid_generator, validation_steps=valid_steps, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "# Best validation model\n",
    "best_idx = int(np.argmax(h.history['val_accuracy']))\n",
    "best_value = np.max(h.history['val_accuracy'])\n",
    "print('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IMMO_mT-AM9"
   },
   "source": [
    "#### Testing\n",
    "Try to improve the results provided in the Moodle competition wiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgh9KqIW-AM-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Load database\n",
    "json_file = 'xview_ann_test.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJr_-xCt-AM-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "anns = []\n",
    "for json_img, json_ann in zip(json_data['images'], json_data['annotations']):\n",
    "    image = GenericImage(json_img['file_name'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    obj = GenericObject()\n",
    "    obj.id = json_ann['id']\n",
    "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "    obj.category = list(categories.values())[json_ann['category_id']-1]\n",
    "    image.add_object(obj)\n",
    "    anns.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGs2zqfv-AM_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# model.load_weights('model_resnet_1.hdf5', by_name=True)\n",
    "y_true, y_pred = [], []\n",
    "for ann in anns:\n",
    "    # Load image\n",
    "    image = load_geoimage(ann.filename)\n",
    "    for obj_pred in ann.objects:\n",
    "        # Generate prediction\n",
    "        warped_image = np.expand_dims(image, 0)\n",
    "        predictions = model.predict(warped_image)\n",
    "        # Save prediction\n",
    "        pred_category = list(categories.values())[np.argmax(predictions)]\n",
    "        pred_score = np.max(predictions)\n",
    "        y_true.append(obj_pred.category)\n",
    "        y_pred.append(pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqYKVsEp-AM_",
    "outputId": "d256367d-744e-487d-f44c-cd106dad3484"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\n",
    "draw_confusion_matrix(cm, categories)\n",
    "\n",
    "# Note. this notebook was run two times, and the first time it actually classified almost instances as small cars instead of buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jD1zLfCd-ANA",
    "outputId": "3a3154f8-c349-4a58-a129-d7aa04a588cb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "####RESULTS FROM THE FIRST RUN (CARS)\n",
    "\n",
    "# Compute the accuracy\n",
    "correct_samples_class = np.diag(cm).astype(float)\n",
    "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
    "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
    "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
    "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
    "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
    "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
    "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
    "for idx in range(len(categories)):\n",
    "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
    "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
    "    tp = cm[idx, idx]\n",
    "    fp = sum(cm[:, idx]) - tp\n",
    "    fn = sum(cm[idx, :]) - tp\n",
    "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
    "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
    "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
    "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
    "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
    "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
    "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
    "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
    "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
    "    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNdH4hNj-ANB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "####RESULTS FROM THE SECOND RUN (BUIlDINGS)\n",
    "\n",
    "# Compute the accuracy\n",
    "correct_samples_class = np.diag(cm).astype(float)\n",
    "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
    "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
    "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
    "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
    "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
    "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
    "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
    "for idx in range(len(categories)):\n",
    "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
    "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
    "    tp = cm[idx, idx]\n",
    "    fp = sum(cm[:, idx]) - tp\n",
    "    fn = sum(cm[idx, :]) - tp\n",
    "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
    "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
    "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
    "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
    "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
    "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
    "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
    "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
    "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
    "    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOPI5zc8-ANB"
   },
   "source": [
    "#### Report\n",
    "\n",
    "You must prepare a report (PDF) describing:\n",
    "* The problems and data sets (briefly).\n",
    "* The process that you have followed to reach your solution for the “xview_recognition” benchmark, including your intermediate results. You must discuss and compare these results properly.\n",
    "* Final network architectures, including optimization algorithms, regularization methods (dropout, data augmentation, etc.), number of layers/parameters, and performance obtained with your model on the train/valid/test data sets, including the plots of the evolution of losses and accuracy.\n",
    "* It would also be very valuable your feedback on the use of “Cesvima” or “Google Colab\" services.\n",
    "\n",
    "In the submission via Moodle, attach your Python (.py) or Jupyter Notebook (.ipynb) source file, including in the report all results of computations attached to the code that generated them.\n",
    "\n",
    "The assignment must be done in groups of 3 students. Each team must submit one submission before Tuesday, April 18th, 2023, 23:55h."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
